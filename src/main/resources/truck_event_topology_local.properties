#Broker host
#kafka.zookeeper.host.port=hadoop-w-0.c.onefold-1.internal:2181
kafka.zookeeper.host.port=zookeeper.internal.hippocamp.io:2181
#Kafka topic to consume.
kafka.topic=truckevent
#Location in ZK for the Kafka spout to store state.
kafka.zkRoot=/truck_event_sprout_local
#Kafka Spout Executors.
spout.thread.count=1

#hdfs bolt settings
hdfs.path=/truck-events-v4
hdfs.url=hdfs://hadoop-m.c.onefold-1.internal:8020
hdfs.file.prefix=truckEvents
#data will be moved from hdfs to the hive partition
#on the first write after the 5th minute.
hdfs.file.rotation.time.minutes=5

#hbase bolt settings
hbase.persist.all.events=false

#hive settings
hive.metastore.url=thrift://hadoop-w-0.c.onefold-1.internal:9083
hive.staging.table.name=truck_events_text_partition
hive.database.name=default

cassandra.nodes=localhost
cassandra.keyspace=testkeyspace


#### CQL for Cassandra Writer Bolts ####
logTruckEventBolt.cql=INSERT INTO TRUCK_EVENT (driverId,truckId, eventTime, eventType, longitude, latitude) values (?,?,?,?,?,?)
writer.cql=INSERT INTO TRUCK_EVENT (driverId,truckId, eventTime, eventType, longitude, latitude) values (?,?,?,?,?,?)
